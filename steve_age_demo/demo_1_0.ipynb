{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Because of the incompatible in the pixdim and dim, we get three images avoid from the dataset:\n",
    "\n",
    "- A00058503\n",
    "- A00058952\n",
    "- A00059344\n",
    "\n",
    "They have neck part in the images. (We've put them in the backup folder.)\n",
    "\n",
    "- A00040181\n",
    "- A00039084\n",
    "\n",
    "these two training images are missing.\n",
    "\n",
    "Since the limit of GPU memory, we've got to resize the input images from (176,256,256) to (110,130,130)\n",
    "\n",
    "**pay attention that for multi-center dataset, we will need to rotate the images to fit in the same size like\n",
    "(130,130,110)**\n",
    "\n",
    "We collect the best shot who has the smallest loss value in the training process.\n",
    "\n",
    "The validation uses the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from preprocess import *\n",
    "\n",
    "# preprocess_main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python demo_1_1.py --num_epochs=1000 \n",
    "!python demo_1_2.py --num_epochs=1000 --MIN_TEST_LOSS=1000.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./log/demo1.1_mine_model.ckpt\n",
      "Model loaded successfully.\n",
      "Subject:  A00027443 , chronological age is  15.0 , predicted age is  [[37.430885]] .\n",
      "INFO:tensorflow:Restoring parameters from ./log/demo1.1_mine_model.ckpt\n",
      "Model loaded successfully.\n",
      "Subject:  A00033748 , chronological age is  58.0 , predicted age is  [[38.36296]] .\n",
      "INFO:tensorflow:Restoring parameters from ./log/demo1.1_mine_model.ckpt\n",
      "Model loaded successfully.\n",
      "Subject:  A00037522 , chronological age is  64.0 , predicted age is  [[40.78564]] .\n",
      "INFO:tensorflow:Restoring parameters from ./log/demo1.1_mine_model.ckpt\n",
      "Model loaded successfully.\n",
      "Subject:  A00057445 , chronological age is  56.0 , predicted age is  [[38.99231]] .\n",
      "INFO:tensorflow:Restoring parameters from ./log/demo1.1_mine_model.ckpt\n",
      "Model loaded successfully.\n",
      "Subject:  A00039353 , chronological age is  52.0 , predicted age is  [[38.913208]] .\n",
      "INFO:tensorflow:Restoring parameters from ./log/demo1.1_mine_model.ckpt\n",
      "Model loaded successfully.\n",
      "Subject:  A00054913 , chronological age is  83.0 , predicted age is  [[41.09427]] .\n",
      "INFO:tensorflow:Restoring parameters from ./log/demo1.1_mine_model.ckpt\n",
      "Model loaded successfully.\n",
      "Subject:  A00043998 , chronological age is  28.0 , predicted age is  [[38.28448]] .\n",
      "INFO:tensorflow:Restoring parameters from ./log/demo1.1_mine_model.ckpt\n",
      "Model loaded successfully.\n",
      "Subject:  A00040182 , chronological age is  71.0 , predicted age is  [[41.97731]] .\n",
      "INFO:tensorflow:Restoring parameters from ./log/demo1.1_mine_model.ckpt\n",
      "Model loaded successfully.\n",
      "Subject:  A00023510 , chronological age is  23.0 , predicted age is  [[36.72813]] .\n",
      "INFO:tensorflow:Restoring parameters from ./log/demo1.1_mine_model.ckpt\n",
      "Model loaded successfully.\n",
      "Subject:  A00028352 , chronological age is  23.0 , predicted age is  [[37.7897]] .\n"
     ]
    }
   ],
   "source": [
    "from preprocess import *\n",
    "from my_tools import *\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "def print_activations(t):\n",
    "    print(t.op.name, ' ', t.get_shape().as_list())\n",
    "\n",
    "\n",
    "def inference(X, keep_prob, is_training_forBN, trivial=True):\n",
    "    l2_loss = 0\n",
    "    with tf.name_scope('l1_conv3d') as scope:\n",
    "        w = tf.Variable(tf.truncated_normal([5,5,5,1,16], stddev=0.1), name='kernel')\n",
    "        b = tf.Variable(tf.constant(0.1,shape=[16]),name='b')\n",
    "        temp_output = tf.nn.bias_add(tf.nn.conv3d(X,w,strides=[1,1,1,1,1],\\\n",
    "                                                        padding='SAME',name='conv3d'),b)\n",
    "        temp_output = tf.layers.batch_normalization(temp_output,training=is_training_forBN)\n",
    "        conv3d = tf.nn.relu(temp_output)\n",
    "        \n",
    "        max_pool = tf.nn.max_pool3d(conv3d,ksize=[1,2,2,2,1],strides=[1,2,2,2,1],\\\n",
    "                                   padding='SAME',name='max_pool3d')\n",
    "        \n",
    "#         l2_loss += tf.nn.l2_loss(w)\n",
    "        \n",
    "        if trivial:\n",
    "            print_activations(conv3d)\n",
    "            print_activations(max_pool)\n",
    "    with tf.name_scope('l2_conv3d') as scope:\n",
    "        w = tf.Variable(tf.truncated_normal([3,3,3,16,32], stddev=0.1), name='kernel')\n",
    "        b = tf.Variable(tf.constant(0.1,shape=[32]),name='b')\n",
    "        temp_output = tf.nn.bias_add(tf.nn.conv3d(max_pool,w,strides=[1,1,1,1,1],\\\n",
    "                                                        padding='SAME',name='conv3d'),b)\n",
    "        temp_output = tf.layers.batch_normalization(temp_output,training=is_training_forBN)\n",
    "        conv3d = tf.nn.relu(temp_output)\n",
    "        \n",
    "        max_pool = tf.nn.max_pool3d(conv3d,ksize=[1,2,2,2,1],strides=[1,2,2,2,1],\\\n",
    "                                   padding='SAME',name='max_pool3d')\n",
    "        \n",
    "#         l2_loss += tf.nn.l2_loss(w)\n",
    "        \n",
    "        if trivial:\n",
    "            print_activations(conv3d)\n",
    "            print_activations(max_pool)\n",
    "    with tf.name_scope('l3_conv3d') as scope:\n",
    "        w = tf.Variable(tf.truncated_normal([3,3,3,32,64], stddev=0.1), name='kernel')\n",
    "        b = tf.Variable(tf.constant(0.1,shape=[64]),name='b')\n",
    "        temp_output = tf.nn.bias_add(tf.nn.conv3d(max_pool,w,strides=[1,1,1,1,1],\\\n",
    "                                                        padding='SAME',name='conv3d'),b)\n",
    "        temp_output = tf.layers.batch_normalization(temp_output,training=is_training_forBN)\n",
    "        conv3d = tf.nn.relu(temp_output)\n",
    "        \n",
    "        max_pool = tf.nn.max_pool3d(conv3d,ksize=[1,2,2,2,1],strides=[1,2,2,2,1],\\\n",
    "                                   padding='SAME',name='max_pool3d')\n",
    "        \n",
    "#         l2_loss += tf.nn.l2_loss(w)\n",
    "        \n",
    "        if trivial:\n",
    "            print_activations(conv3d)\n",
    "            print_activations(max_pool)\n",
    "    with tf.name_scope('l4_conv3d') as scope:\n",
    "        w = tf.Variable(tf.truncated_normal([3,3,3,64,64], stddev=0.1), name='kernel')\n",
    "        b = tf.Variable(tf.constant(0.1,shape=[64]),name='b')\n",
    "        temp_output = tf.nn.bias_add(tf.nn.conv3d(max_pool,w,strides=[1,1,1,1,1],\\\n",
    "                                                        padding='SAME',name='conv3d'),b)\n",
    "        temp_output = tf.layers.batch_normalization(temp_output,training=is_training_forBN)\n",
    "        conv3d = tf.nn.relu(temp_output)\n",
    "        \n",
    "        max_pool = tf.nn.max_pool3d(conv3d,ksize=[1,2,2,2,1],strides=[1,2,2,2,1],\\\n",
    "                                   padding='SAME',name='max_pool3d')\n",
    "        \n",
    "#         l2_loss += tf.nn.l2_loss(w)\n",
    "        \n",
    "        if trivial:\n",
    "            print_activations(conv3d)\n",
    "            print_activations(max_pool)\n",
    "    with tf.name_scope('l5_conv3d') as scope:  # temp\n",
    "        w = tf.Variable(tf.truncated_normal([3,3,3,64,64], stddev=0.1), name='kernel')\n",
    "        b = tf.Variable(tf.constant(0.1,shape=[64]),name='b')\n",
    "        temp_output = tf.nn.bias_add(tf.nn.conv3d(max_pool,w,strides=[1,1,1,1,1],\\\n",
    "                                                        padding='SAME',name='conv3d'),b)\n",
    "        temp_output = tf.layers.batch_normalization(temp_output,training=is_training_forBN)\n",
    "        conv3d = tf.nn.relu(temp_output)\n",
    "        \n",
    "        max_pool = tf.nn.max_pool3d(conv3d,ksize=[1,2,2,2,1],strides=[1,2,2,2,1],\\\n",
    "                                   padding='SAME',name='max_pool3d')\n",
    "        \n",
    "#         l2_loss += tf.nn.l2_loss(w)\n",
    "        \n",
    "        if trivial:\n",
    "            print_activations(conv3d)\n",
    "            print_activations(max_pool)\n",
    "    with tf.name_scope('l6_fc') as scope:\n",
    "        max_pool_shape = max_pool.get_shape().as_list()\n",
    "        temp_shape = 1\n",
    "        for i in max_pool_shape[1:]:\n",
    "            temp_shape *= i\n",
    "        fc_input = tf.reshape(max_pool, [-1, temp_shape])\n",
    "        w = tf.Variable(tf.truncated_normal([temp_shape,512],stddev=0.1),name='w')\n",
    "        b = tf.Variable(tf.constant(0.1,shape=[512]),name='b')\n",
    "        temp_output = tf.matmul(fc_input,w) + b\n",
    "        temp_output = tf.layers.batch_normalization(temp_output,training=is_training_forBN)\n",
    "        fc_out = tf.nn.relu(temp_output, name='fc_out1')\n",
    "        dropout = tf.nn.dropout(fc_out,keep_prob=keep_prob, name='dropout1')\n",
    "        \n",
    "        l2_loss += tf.nn.l2_loss(w)\n",
    "        \n",
    "        if trivial:\n",
    "            print_activations(fc_out)\n",
    "            print_activations(dropout)\n",
    "    with tf.name_scope('l7_fc') as scope:\n",
    "        w = tf.Variable(tf.truncated_normal([512,128],stddev=0.1),name='w')\n",
    "        b = tf.Variable(tf.constant(0.1,shape=[128]),name='b')\n",
    "        temp_output = tf.matmul(fc_out,w) + b\n",
    "        temp_output = tf.layers.batch_normalization(temp_output,training=is_training_forBN)\n",
    "        fc_out = tf.nn.relu(temp_output, name='fc_out2')\n",
    "        dropout = tf.nn.dropout(fc_out,keep_prob=keep_prob, name='dropout2')\n",
    "        \n",
    "        l2_loss += tf.nn.l2_loss(w)\n",
    "        \n",
    "        if trivial:\n",
    "            print_activations(fc_out)\n",
    "            print_activations(dropout)\n",
    "    with tf.name_scope('l8_fc') as scope:\n",
    "        w = tf.Variable(tf.truncated_normal([128,1],stddev=0.1),name='w')\n",
    "        b = tf.Variable(tf.constant(0.1,shape=[1]),name='b')\n",
    "        \n",
    "        final_output = tf.add(tf.matmul(dropout,w), b, name='final_output')\n",
    "        \n",
    "        l2_loss += tf.nn.l2_loss(w)\n",
    "\n",
    "        if trivial:\n",
    "            print_activations(final_output)\n",
    "    \n",
    "    return final_output, l2_loss\n",
    "        \n",
    "def get_loss(predict_batches,label_batches,l2_loss):\n",
    "    with tf.name_scope('cross_entropy'):\n",
    "        cost = tf.reduce_mean(tf.square(predict_batches - label_batches)) + 1e-6 * l2_loss\n",
    "    return cost\n",
    "\n",
    "\n",
    "\n",
    "def test_single_subject(phe_index):\n",
    "    with tf.Graph().as_default():\n",
    "        phe = pd.read_csv('./phenotypics.csv', sep=',',header=0)\n",
    "        sub_id = phe['id'][phe_index]\n",
    "#         arr = np.load('./data_npy/mean_subtracted/'+sub_id+'.npy')\n",
    "        arr = np.load('./data_npy/origin/'+sub_id+'.npy')\n",
    "        arr = arr.astype(np.float32)\n",
    "        arr_shape = arr.shape\n",
    "        label = phe['age'][phe_index]\n",
    "        \n",
    "        tf_arr = tf.placeholder(tf.float32,shape=arr_shape)\n",
    "        tf_label = tf.placeholder(tf.float32)\n",
    "        X = tf.reshape(arr, [-1]+list(arr_shape)+[1])\n",
    "        keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "        \n",
    "        is_training_forBN = tf.placeholder(tf.bool, name='is_training_forBN')\n",
    "        \n",
    "        predicted_age,l2_loss = inference(X,keep_prob,is_training_forBN,trivial=False)\n",
    "\n",
    "#         loss = get_loss(predicted_age,label_batch,l2_loss)\n",
    "#         acc = get_accuracy(predicted_age,label_batch)\n",
    "    \n",
    "        saver = tf.train.Saver()\n",
    "#         pdb.set_trace()\n",
    "\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            saver.restore(sess, './log/demo1.1_mine_model.ckpt')\n",
    "            print('Model loaded successfully.')\n",
    "                \n",
    "            p_age = sess.run(predicted_age,feed_dict={keep_prob:1.0,\n",
    "                                              is_training_forBN:False,\n",
    "                                              tf_arr:arr,\n",
    "                                              tf_label:label})\n",
    "            print('Subject: ',sub_id,', chronological age is ',label,', predicted age is ',p_age,'.')\n",
    "    return\n",
    "for i in range(10):\n",
    "    test_single_subject(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(age_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(age_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
