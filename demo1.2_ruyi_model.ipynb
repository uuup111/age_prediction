{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replication of Ruyi's code.\n",
    "\n",
    "Dataset: IXI\n",
    "\n",
    "10% for test, 90% for training. (Option: k-folds cross validation, not implemented yet.)\n",
    "\n",
    "Using ruyi's model code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's get started to train!\n",
      "<class 'numpy.float32'>\n",
      "<class 'list'>\n",
      "<class 'int'>\n",
      "<class 'float'>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "a float is required",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfRangeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m~/vpython/vp3.5.2/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1292\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1293\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/vpython/vp3.5.2/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1276\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1277\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/vpython/vp3.5.2/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1366\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOutOfRangeError\u001b[0m: End of sequence\n\t [[{{node IteratorGetNext}} = IteratorGetNext[output_shapes=[<unknown>, <unknown>], output_types=[DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](IteratorFromStringHandleV2)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOutOfRangeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-76dc88e23349>\u001b[0m in \u001b[0;36mrun_training\u001b[0;34m()\u001b[0m\n\u001b[1;32m    186\u001b[0m                                                                 feed_dict={keep_prob:1.0,\n\u001b[0;32m--> 187\u001b[0;31m                                                                           handle:test_iterator_handle})\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;31m#                                 pdb.set_trace()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/vpython/vp3.5.2/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    886\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 887\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    888\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/vpython/vp3.5.2/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1109\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1110\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1111\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/vpython/vp3.5.2/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1285\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1286\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1287\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/vpython/vp3.5.2/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1308\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOutOfRangeError\u001b[0m: End of sequence\n\t [[{{node IteratorGetNext}} = IteratorGetNext[output_shapes=[<unknown>, <unknown>], output_types=[DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](IteratorFromStringHandleV2)]]\n\nCaused by op 'IteratorGetNext', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/woody/vpython/vp3.5.2/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/woody/vpython/vp3.5.2/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/woody/vpython/vp3.5.2/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 499, in start\n    self.io_loop.start()\n  File \"/home/woody/vpython/vp3.5.2/lib/python3.5/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n    self._callback(*self._args)\n  File \"/home/woody/vpython/vp3.5.2/lib/python3.5/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/home/woody/vpython/vp3.5.2/lib/python3.5/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/woody/vpython/vp3.5.2/lib/python3.5/site-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/home/woody/vpython/vp3.5.2/lib/python3.5/site-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/home/woody/vpython/vp3.5.2/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 346, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/woody/vpython/vp3.5.2/lib/python3.5/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/woody/vpython/vp3.5.2/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 259, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/woody/vpython/vp3.5.2/lib/python3.5/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/woody/vpython/vp3.5.2/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 513, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/woody/vpython/vp3.5.2/lib/python3.5/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/woody/vpython/vp3.5.2/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/woody/vpython/vp3.5.2/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/woody/vpython/vp3.5.2/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2817, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/woody/vpython/vp3.5.2/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2843, in _run_cell\n    return runner(coro)\n  File \"/home/woody/vpython/vp3.5.2/lib/python3.5/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/woody/vpython/vp3.5.2/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3018, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/woody/vpython/vp3.5.2/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3183, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/woody/vpython/vp3.5.2/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3265, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-76dc88e23349>\", line 330, in <module>\n    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\n  File \"/home/woody/vpython/vp3.5.2/lib/python3.5/site-packages/tensorflow/python/platform/app.py\", line 125, in run\n    _sys.exit(main(argv))\n  File \"<ipython-input-6-76dc88e23349>\", line 278, in main\n    run_training()\n  File \"<ipython-input-6-76dc88e23349>\", line 132, in run_training\n    arr_batch,label_batch = iterator.get_next()\n  File \"/home/woody/vpython/vp3.5.2/lib/python3.5/site-packages/tensorflow/python/data/ops/iterator_ops.py\", line 420, in get_next\n    name=name)), self._output_types,\n  File \"/home/woody/vpython/vp3.5.2/lib/python3.5/site-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 2069, in iterator_get_next\n    output_shapes=output_shapes, name=name)\n  File \"/home/woody/vpython/vp3.5.2/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/woody/vpython/vp3.5.2/lib/python3.5/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/home/woody/vpython/vp3.5.2/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 3272, in create_op\n    op_def=op_def)\n  File \"/home/woody/vpython/vp3.5.2/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1768, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nOutOfRangeError (see above for traceback): End of sequence\n\t [[{{node IteratorGetNext}} = IteratorGetNext[output_shapes=[<unknown>, <unknown>], output_types=[DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](IteratorFromStringHandleV2)]]\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-76dc88e23349>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[0;31m#       help='Directory with the training data.')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0mFLAGS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munparsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_known_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0munparsed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/vpython/vp3.5.2/lib/python3.5/site-packages/tensorflow/python/platform/app.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv)\u001b[0m\n\u001b[1;32m    123\u001b[0m   \u001b[0;31m# Call the main function, passing through any arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m   \u001b[0;31m# to the final program.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m   \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-76dc88e23349>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(_)\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marr_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m     \u001b[0mrun_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m     \u001b[0mrun_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-76dc88e23349>\u001b[0m in \u001b[0;36mrun_training\u001b[0;34m()\u001b[0m\n\u001b[1;32m    201\u001b[0m                             \u001b[0mtest_steps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m                             print('Step %d: training_loss = %.2f (%.3f sec)\\n (val_loss)test_loss = %.2f' \n\u001b[0;32m--> 203\u001b[0;31m                                   %(step,loss_value,duration,test_loss))\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mtest_loss\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmin_test_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: a float is required"
     ]
    }
   ],
   "source": [
    "\n",
    "from preprocess import *\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "\n",
    "FLAGS = None\n",
    "n_classes = 1\n",
    "\n",
    "def conv3d(x, W):\n",
    "    return tf.nn.conv3d(x, W, strides=[1,1,1,1,1], padding='SAME')\n",
    "def maxpool3d(x):\n",
    "    return tf.nn.max_pool3d(x, ksize=[1,2,2,2,1], strides=[1,2,2,2,1], padding='SAME')\n",
    "def convolutional_neural_network(x,dropout_rate):\n",
    "    initializer = tf.contrib.layers.xavier_initializer()\n",
    "    weights = {'W_conv1':tf.Variable(initializer([3,3,3,1,8]), name=\"W_conv1\"),\n",
    "               'W_conv2':tf.Variable(initializer([3,3,3,8,16]), name=\"W_conv2\"),\n",
    "               'W_conv3':tf.Variable(initializer([3,3,3,16,32]), name=\"W_conv3\"),\n",
    "               'W_conv4':tf.Variable(initializer([3,3,3,32,64]), name=\"W_conv4\"),\n",
    "               'W_conv5':tf.Variable(initializer([3,3,3,64,128]), name=\"W_conv5\"),\n",
    "#                'W_fc':tf.Variable(initializer([temp_shape,1024]), name=\"W_fc\"),\n",
    "               'W_out':tf.Variable(initializer([1024, n_classes]), name=\"W_out\")}\n",
    "\n",
    "    biases = {'b_conv1':tf.Variable(initializer([8]), name=\"b_conv1\"),\n",
    "               'b_conv2':tf.Variable(initializer([16]), name=\"b_conv2\"),\n",
    "              'b_conv3':tf.Variable(initializer([32]), name=\"b_conv3\"),\n",
    "              'b_conv4':tf.Variable(initializer([64]), name=\"b_conv4\"),\n",
    "              'b_conv5':tf.Variable(initializer([128]), name=\"b_conv5\"),\n",
    "               'b_fc':tf.Variable(initializer([1024]), name=\"b_fc\"),\n",
    "               'b_out':tf.Variable(initializer([n_classes]), name=\"b_out\")}\n",
    "\n",
    "#     x = tf.reshape(x, shape=[-1, IMG_SIZE_PX, IMG_SIZE_PX, SLICE_COUNT, 1])\n",
    "\n",
    "    conv1 = tf.nn.relu(conv3d(x, weights['W_conv1']) + biases['b_conv1'])\n",
    "    conv1 = tf.nn.dropout(conv1, dropout_rate)\n",
    "    conv1 = maxpool3d(conv1)\n",
    "    \n",
    "    conv2 = tf.nn.relu(conv3d(conv1, weights['W_conv2']) + biases['b_conv2'])\n",
    "    conv2 = tf.nn.dropout(conv2, dropout_rate)\n",
    "    conv2 = maxpool3d(conv2)\n",
    "\n",
    "    conv3 = tf.nn.relu(conv3d(conv2, weights['W_conv3']) + biases['b_conv3'])\n",
    "    conv3 = tf.nn.dropout(conv3, dropout_rate)\n",
    "    conv3 = maxpool3d(conv3)\n",
    "\n",
    "    conv4 = tf.nn.relu(conv3d(conv3, weights['W_conv4']) + biases['b_conv4'])\n",
    "    conv4 = tf.nn.dropout(conv4, dropout_rate)\n",
    "    conv4 = maxpool3d(conv4)\n",
    "\n",
    "    conv5 = tf.nn.relu(conv3d(conv4, weights['W_conv5']) + biases['b_conv5'])\n",
    "    conv5 = tf.nn.dropout(conv5, dropout_rate)\n",
    "    conv5 = maxpool3d(conv5)\n",
    "    \n",
    "    max_pool_shape = conv5.get_shape().as_list()\n",
    "    temp_shape = 1\n",
    "    for i in max_pool_shape[1:]:\n",
    "        temp_shape *= i\n",
    "    fc_input = tf.reshape(conv5, [-1, temp_shape])\n",
    "    \n",
    "    w = tf.Variable(tf.truncated_normal([temp_shape,1024],stddev=0.1),name='W_fc')\n",
    "    fc = tf.matmul(fc_input, w)+biases['b_fc']\n",
    "    fc = tf.nn.dropout(fc, dropout_rate)\n",
    "\n",
    "    output = tf.add(tf.matmul(fc, weights['W_out']),biases['b_out'],name=\"output\")\n",
    "\n",
    "#     return output[0]\n",
    "    return output\n",
    "\n",
    "\n",
    "def print_activations(t):\n",
    "    print(t.op.name, ' ', t.get_shape().as_list())\n",
    "\n",
    "\n",
    "def decode(serialized_example):\n",
    "    features = tf.parse_single_example(\n",
    "        serialized_example,\n",
    "        features={\n",
    "            'arr_raw':tf.FixedLenFeature([],tf.string),\n",
    "            'label': tf.FixedLenFeature([],tf.float32),\n",
    "        }\n",
    "    )\n",
    "    arr = tf.decode_raw(features['arr_raw'],tf.float32)\n",
    "    arr = tf.reshape(arr,list(FLAGS.arr_shape))\n",
    "#     arr = tf.cast(arr,tf.int32)\n",
    "#     label = tf.cast(features['label'],tf.int32)\n",
    "    label = features['label']\n",
    "    \n",
    "    return arr,label\n",
    "\n",
    "\n",
    "def get_iterator(for_training=True,num_epochs=1):\n",
    "    if not num_epochs:\n",
    "        num_epochs = None\n",
    "    root_dir = FLAGS.root_dir\n",
    "    filename = os.path.join(root_dir,('training' if for_training else 'test')+'.tfrecords')\n",
    "\n",
    "    with tf.name_scope('input'):\n",
    "        dataset = tf.data.TFRecordDataset(filename)\n",
    "#         pdb.set_trace()\n",
    "        dataset = dataset.map(decode)\n",
    "        if for_training:\n",
    "            dataset = dataset.repeat(num_epochs)\n",
    "        dataset = dataset.batch(FLAGS.batch_size)\n",
    "        if for_training:\n",
    "            train_iterator = dataset.make_one_shot_iterator()\n",
    "            val_iterator = dataset.make_one_shot_iterator()\n",
    "            iterators = [train_iterator,val_iterator]\n",
    "        else:\n",
    "            test_iterator = dataset.make_initializable_iterator()\n",
    "            iterators = [test_iterator]\n",
    "\n",
    "        \n",
    "    return iterators\n",
    "\n",
    "def get_loss(predict_batches,label_batches):\n",
    "    with tf.name_scope('RMSE'):\n",
    "        loss = tf.reduce_mean(tf.square(predict_batches - label_batches)) \n",
    "    return loss\n",
    "\n",
    "    \n",
    "def run_training():\n",
    "    with tf.Graph().as_default():\n",
    "        num_epochs = FLAGS.num_epochs\n",
    "        iterators = get_iterator(num_epochs=num_epochs)\n",
    "        handle = tf.placeholder(tf.string,shape=[])\n",
    "        iterator = tf.data.Iterator.from_string_handle(handle, iterators[0].output_types)\n",
    "        arr_batch,label_batch = iterator.get_next()\n",
    "        \n",
    "#         pdb.set_trace()\n",
    "\n",
    "        X = tf.reshape(arr_batch, [-1]+list(FLAGS.arr_shape)+[1])\n",
    "        keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "        \n",
    "        prediction = convolutional_neural_network(X,keep_prob)\n",
    "        loss = get_loss(prediction,label_batch)\n",
    "        train_op = tf.train.AdamOptimizer(learning_rate=7e-5).minimize(loss)        \n",
    "    \n",
    "        init_op = tf.group(tf.global_variables_initializer(),\n",
    "                           tf.local_variables_initializer())\n",
    "    \n",
    "        saver = tf.train.Saver()\n",
    "    \n",
    "        with tf.Session() as sess:\n",
    "            losses = []\n",
    "            steps = []\n",
    "            \n",
    "            test_losses = []\n",
    "            test_steps = []\n",
    "            \n",
    "#             pdb.set_trace()\n",
    "            sess.run(init_op)\n",
    "            train_iterator_handle = sess.run(iterators[0].string_handle())\n",
    "            val_iterator_handle = sess.run(iterators[1].string_handle())\n",
    "            \n",
    "            test_iterator = get_iterator(for_training=False)[0]\n",
    "            test_iterator_handle = sess.run(test_iterator.string_handle())\n",
    "            \n",
    "            print('Let\\'s get started to train!')\n",
    "            \n",
    "            try:\n",
    "                step = 0\n",
    "                min_test_loss = 300.0\n",
    "                while True:\n",
    "                    start_time = time.time()\n",
    "                    sess.run([train_op],\n",
    "                              feed_dict={keep_prob:0.8,\n",
    "                                        handle:train_iterator_handle})\n",
    "\n",
    "                    loss_value = sess.run([loss],\n",
    "                                        feed_dict={keep_prob:1.0,\n",
    "                                                  handle:val_iterator_handle})\n",
    "                    duration = time.time() - start_time\n",
    "\n",
    "                    if step % 100 == 0:\n",
    "                        sess.run(test_iterator.initializer)\n",
    "                        test_predicted_ages = []\n",
    "                        test_labels = []\n",
    "                        try:\n",
    "                            while True:\n",
    "                                test_predicted_age,test_label = sess.run([prediction,label_batch],\n",
    "                                                                feed_dict={keep_prob:1.0,\n",
    "                                                                          handle:test_iterator_handle})\n",
    "#                                 pdb.set_trace()\n",
    "                                test_predicted_ages.append(test_predicted_age)\n",
    "                                test_labels.append(test_label)\n",
    "                        except tf.errors.OutOfRangeError:\n",
    "#                             pdb.set_trace()\n",
    "                            test_predicted_ages = np.concatenate(tuple(test_predicted_ages))\n",
    "                            test_labels = np.concatenate(tuple(test_labels))\n",
    "                            test_loss = (get_loss(test_predicted_ages,test_labels)).eval()\n",
    "                            print(type(test_loss))\n",
    "                            print(type(loss_value))\n",
    "                            print(type(step))\n",
    "                            print(type(duration))\n",
    "                            test_losses.append(test_loss)\n",
    "                            test_steps.append(step)\n",
    "                            print('Step %d: training_loss = %.2f (%.3f sec)\\n (val_loss)test_loss = %.2f' \n",
    "                                  %(step,loss_value,duration,test_loss))\n",
    "                            \n",
    "                            if test_loss < min_test_loss:\n",
    "                                min_test_loss = test_loss\n",
    "                                print('best shot model: test_loss = %.2f, step = %d' %(min_test_loss,step))\n",
    "                                if step > 100:\n",
    "                                    save_path = saver.save(sess, FLAGS.saver_dir)\n",
    "                                    print('model saved successfully.')\n",
    "                                    \n",
    "                    steps.append(step)\n",
    "                    losses.append(loss_value)\n",
    "                    step += 1\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                print('Done training for %d epochs, %d steps.' %(num_epochs,step))\n",
    "            \n",
    "            f, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,5))\n",
    "            ax1.plot(steps, losses)\n",
    "            ax1.plot(test_steps,test_losses)\n",
    "            ax1.set_title('trainning loss')\n",
    "            ax1.grid(True)\n",
    "    return\n",
    " \n",
    "    \n",
    "def run_test():\n",
    "    with tf.Graph().as_default():\n",
    "        handle = tf.placeholder(tf.string,shape=[])\n",
    "        test_iterator = get_iterator(for_training=False)[0]\n",
    "        iterator = tf.data.Iterator.from_string_handle(handle, test_iterator.output_types)\n",
    "        arr_batch,label_batch = iterator.get_next()\n",
    "        X = tf.reshape(arr_batch, [-1]+list(FLAGS.arr_shape)+[1])\n",
    "        keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "        \n",
    "        prediction = convolutional_neural_network(X,keep_prob)\n",
    "        loss = get_loss(prediction,label_batch)\n",
    "    \n",
    "        saver = tf.train.Saver()\n",
    "#         pdb.set_trace()\n",
    "        with tf.Session() as sess:\n",
    "            saver.restore(sess, FLAGS.saver_dir)\n",
    "            print('Model loaded successfully.')\n",
    "            test_iterator_handle = sess.run(test_iterator.string_handle())\n",
    "            sess.run(test_iterator.initializer)\n",
    "            test_predicted_ages = []\n",
    "            test_labels = []\n",
    "            try:\n",
    "                while True:\n",
    "                    test_predicted_age,test_label = sess.run([prediction, label_batch],\n",
    "                                                    feed_dict={keep_prob:1.0,\n",
    "                                                              handle:test_iterator_handle})\n",
    "                    test_predicted_ages.append(test_predicted_age)\n",
    "                    test_labels.append(test_label)\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                test_predicted_ages = np.concatenate(tuple(test_predicted_ages))\n",
    "                test_labels = np.concatenate(tuple(test_labels))\n",
    "                \n",
    "                test_loss = (get_loss(test_predicted_ages,test_labels)).eval()\n",
    "                \n",
    "                print('test_loss(RMSE) = %.2f.' \n",
    "                                  %(test_loss))\n",
    "            plt.title('Test Data')\n",
    "            plt.xlabel('Chronological Age')\n",
    "            plt.ylabel('Brain Age (Predicted)')\n",
    "            plt.xlim(0, 100)\n",
    "            plt.ylim(0, 100)\n",
    "            for i in range(len(test_labels)):\n",
    "                plt.scatter(test_labels[i], test_predicted_ages[i], c = 'blue',s=1)\n",
    "            plt.gca().set_aspect('equal', adjustable='box')\n",
    "    return\n",
    "\n",
    "\n",
    "def main(_):\n",
    "#     pdb.set_trace()\n",
    "    arr = np.load('./IXI_npy/mean_npy.npy')\n",
    "    FLAGS.arr_shape = arr.shape\n",
    "    \n",
    "    run_training()\n",
    "    run_test()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--saver_dir',\n",
    "                       type=str,\n",
    "                       default=\"./log/demo1.1_ruyi_model.ckpt\",\n",
    "                       help='Directory to save checkpoint.')\n",
    "    parser.add_argument('--l2_epsilon',\n",
    "                       type=float,\n",
    "                       default=1e-6,\n",
    "                       help='L2 regularization parameter.')\n",
    "    parser.add_argument('--root_dir',\n",
    "                       type=str,\n",
    "                       default='./',\n",
    "                       help='Where is the tfrecord file.')\n",
    "    parser.add_argument('--sizeof_kernel_1',\n",
    "                        type=int,\n",
    "                        default=16,\n",
    "                        help='kernel size of 1st hidden layer.')\n",
    "    parser.add_argument('--batch_size',\n",
    "                        type=int,\n",
    "                        default=10,\n",
    "                        help='Batch size.')\n",
    "#     parser.add_argument(\n",
    "#       '--learning_rate',\n",
    "#       type=float,\n",
    "#       default=0.01,\n",
    "#       help='Initial learning rate.')\n",
    "    parser.add_argument('--num_epochs',\n",
    "                        type=int,\n",
    "                        default=50,\n",
    "                        help='Number of epochs to run trainer.')\n",
    "#     parser.add_argument(\n",
    "#       '--hidden1',\n",
    "#       type=int,\n",
    "#       default=128,\n",
    "#       help='Number of units in hidden layer 1.')\n",
    "#     parser.add_argument(\n",
    "#       '--hidden2',\n",
    "#       type=int,\n",
    "#       default=32,\n",
    "#       help='Number of units in hidden layer 2.')\n",
    "\n",
    "#     parser.add_argument(\n",
    "#       '--train_dir',\n",
    "#       type=str,\n",
    "#       default='/tmp/data',\n",
    "#       help='Directory with the training data.')\n",
    "    FLAGS, unparsed = parser.parse_known_args()\n",
    "    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_tensor = tf.random_normal([2,2])\n",
    "a = temp_tensor.get_shape().as_list()\n",
    "with tf.Session() as sess:\n",
    "#     print(sess.run(temp_tensor))\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
