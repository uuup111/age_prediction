{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "from dev_tools.my_tools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in path: ./log/main.ckpt\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.concat?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 1)\n",
      "Model saved in path: ./log/m1/model_1.ckpt\n",
      "(?, 1)\n",
      "Model saved in path: ./log/m2/model_2.ckpt\n"
     ]
    }
   ],
   "source": [
    "def bb_net(x):\n",
    "    with tf.name_scope('l1') as scope:\n",
    "        x_shape = x.get_shape().as_list()\n",
    "        w = tf.Variable(tf.random_normal([x_shape[1], 5]),name='w')\n",
    "        b = tf.Variable(tf.random_normal([5]),name='b')\n",
    "        out = tf.nn.sigmoid(tf.matmul(x, w) + b,name='out')\n",
    "    with tf.name_scope('l2') as scope:\n",
    "        w = tf.Variable(tf.random_normal([5, 1]),name='w')\n",
    "        b = tf.Variable(tf.random_normal([1]),name='b')\n",
    "        out = tf.nn.sigmoid(tf.matmul(out, w) + b,name='out')\n",
    "    return out\n",
    "\n",
    "def get_loss(predict_batches,label_batches,l2_loss):\n",
    "    predict_batches = tf.reshape(predict_batches,[-1,1])\n",
    "    label_batches = tf.reshape(label_batches,[-1,1])\n",
    "    cost = tf.reduce_mean(tf.square(predict_batches - label_batches))\n",
    "    return cost\n",
    "\n",
    "def run_model(log_file):\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    input1 = tf.placeholder(tf.float32, [None, 2])\n",
    "    output1 = bb_net(input1) # 2-20-3 network\n",
    "#     output1 = bb_net_rename(input1)\n",
    "    print(output1.shape)\n",
    "\n",
    "\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init_op)\n",
    "    #     sess.run(output1,feed_dict={input1:np.random.rand(3,2)})\n",
    "        save_path = saver.save(sess, log_file)\n",
    "        print(\"Model saved in path: %s\" % save_path)\n",
    "    return\n",
    "\n",
    "run_model(\"./log/m1/model_1.ckpt\")\n",
    "run_model(\"./log/m2/model_2.ckpt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------- - ----------------------------------------\n",
      "tensor_name:  l1/b\n",
      "tensor_name:  l2/w\n",
      "tensor_name:  l2/b\n",
      "tensor_name:  l1/w\n",
      "---------------------------------------- - ----------------------------------------\n",
      "tensor_name:  l1/b\n",
      "[-0.22517745 -0.19252679  1.9404557   1.1618617   0.7309009 ]\n",
      "tensor_name:  l1/w\n",
      "[[ 2.1081982  -0.0653644   0.71789426 -0.8337884   0.49091208]\n",
      " [-0.79259986 -0.57869947  2.2429605  -0.88159746 -1.350748  ]]\n",
      "tensor_name:  l2/b\n",
      "[0.9156851]\n",
      "tensor_name:  l2/w\n",
      "[[-0.04598412]\n",
      " [ 0.39964706]\n",
      " [ 0.7660096 ]\n",
      " [ 1.358788  ]\n",
      " [-0.19824822]]\n",
      "---------------------------------------- - ----------------------------------------\n",
      "tensor_name:  l1/b\n",
      "tensor_name:  l2/w\n",
      "tensor_name:  l2/b\n",
      "tensor_name:  l1/w\n",
      "---------------------------------------- - ----------------------------------------\n",
      "tensor_name:  l1/b\n",
      "[ 1.174079    0.13221252  1.8445915  -1.0480018  -0.8405697 ]\n",
      "tensor_name:  l1/w\n",
      "[[-1.3923197  -1.0091283  -0.604495   -1.1805317  -1.4689256 ]\n",
      " [-0.26353896  0.56431895  0.8425082  -1.6075876   0.760832  ]]\n",
      "tensor_name:  l2/b\n",
      "[-0.08572993]\n",
      "tensor_name:  l2/w\n",
      "[[-0.59722185]\n",
      " [-1.1657702 ]\n",
      " [-0.80629337]\n",
      " [ 0.4921196 ]\n",
      " [-0.3412767 ]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python import pywrap_tensorflow \n",
    "from tensorflow.python.tools import inspect_checkpoint as chkp\n",
    "\n",
    "def show_ckpt(filename):\n",
    "    reader = pywrap_tensorflow.NewCheckpointReader(filename) \n",
    "    var_to_shape_map = reader.get_variable_to_shape_map() \n",
    "#     print(var_to_shape_map)\n",
    "    print_sep()\n",
    "    for key in var_to_shape_map: \n",
    "        print(\"tensor_name: \", key)\n",
    "\n",
    "\n",
    "    print_sep()\n",
    "    chkp.print_tensors_in_checkpoint_file(filename, tensor_name='', all_tensors=True)\n",
    "    \n",
    "show_ckpt(\"./log/m1/model_1.ckpt\")\n",
    "show_ckpt(\"./log/m2/model_2.ckpt\")\n",
    "# show_ckpt('./log/main.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(x1,x2):\n",
    "    with tf.name_scope('net1') as scope:\n",
    "        with tf.name_scope('l1') as scope:\n",
    "            x_shape = x1.get_shape().as_list()\n",
    "            w = tf.Variable(tf.random_normal([x_shape[1], 5]),name='w')\n",
    "            b = tf.Variable(tf.random_normal([5]),name='b')\n",
    "        net1_out = tf.nn.sigmoid(tf.matmul(x1, w) + b)\n",
    "    with tf.name_scope('net2') as scope:\n",
    "        with tf.name_scope('l1') as scope:\n",
    "            x_shape = x2.get_shape().as_list()\n",
    "            w = tf.Variable(tf.random_normal([x_shape[1], 5]),name='w')\n",
    "            b = tf.Variable(tf.random_normal([5]),name='b')\n",
    "        net2_out = tf.nn.sigmoid(tf.matmul(x2, w) + b)\n",
    "    \n",
    "#     pdb.set_trace()\n",
    "    with tf.name_scope('final_layer') as scope:\n",
    "        w = tf.Variable(tf.random_normal([10, 1]),name='w')\n",
    "        b = tf.Variable(tf.random_normal([1]),name='b')\n",
    "        final_out = tf.nn.sigmoid(tf.matmul(tf.concat([net1_out,net2_out],1), w) + b)\n",
    "\n",
    "    return final_out \n",
    "\n",
    "def run_main():\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    input1 = tf.placeholder(tf.float32, [None, 2])\n",
    "    input2 = tf.placeholder(tf.float32, [None, 2])\n",
    "    output = inference(input1,input2) \n",
    "\n",
    "#     init_op = tf.global_variables_initializer()\n",
    "#     saver = tf.train.Saver()\n",
    "#     with tf.Session() as sess:\n",
    "#         sess.run(init_op)\n",
    "#         save_path = saver.save(sess, './log/main.ckpt')\n",
    "#         print(\"Model saved in path: %s\" % './log/main.ckpt')\n",
    "#     return\n",
    "    \n",
    "    saver1 = tf.train.Saver({'l1/b':'net1/l1/b'})\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init_op)\n",
    "        cons_input = np.random.rand(3,2)\n",
    "        sess.run(output1,feed_dict={input1:cons_input,input2:cons_input})\n",
    "        save_path = saver.save(sess, log_file)\n",
    "        print(\"Model saved in path: %s\" % save_path)\n",
    "    return  \n",
    "\n",
    "run_main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_input = np.random.rand(3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./log/m1/model_1.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ./log/m1/model_1.ckpt\n",
      "[[0.6998952  0.42184424 0.9357194  0.6366171  0.6916014 ]\n",
      " [0.767608   0.43084663 0.9307523  0.62652844 0.7272433 ]\n",
      " [0.29320782 0.33458742 0.9794445  0.59869456 0.39708373]]\n",
      "INFO:tensorflow:Froze 2 variables.\n",
      "INFO:tensorflow:Converted 2 variables to const ops.\n",
      "INFO:tensorflow:Restoring parameters from ./log/m2/model_2.ckpt\n",
      "[[0.5864791  0.41253614 0.83595526 0.12428858 0.17414013]\n",
      " [0.5452906  0.36942482 0.81458646 0.12073739 0.13997047]\n",
      " [0.7179354  0.6464656  0.92809665 0.08064602 0.448617  ]]\n",
      "INFO:tensorflow:Froze 2 variables.\n",
      "INFO:tensorflow:Converted 2 variables to const ops.\n",
      "Tensor(\"import/l1/out:0\", shape=(?, 5), dtype=float32)\n",
      "Tensor(\"import_1/l1/out:0\", shape=(?, 5), dtype=float32)\n",
      "[[0.6998952  0.42184424 0.9357194  0.6366171  0.6916014 ]\n",
      " [0.767608   0.43084663 0.9307523  0.62652844 0.7272433 ]\n",
      " [0.29320782 0.33458742 0.9794445  0.59869456 0.39708373]]\n",
      "[[ 2.1081982  -0.0653644   0.71789426 -0.8337884   0.49091208]\n",
      " [-0.79259986 -0.57869947  2.2429605  -0.88159746 -1.350748  ]]\n",
      "[[-1.3923197  -1.0091283  -0.604495   -1.1805317  -1.4689256 ]\n",
      " [-0.26353896  0.56431895  0.8425082  -1.6075876   0.760832  ]]\n",
      "Model saved in path: ./log/comb/main.ckpt\n",
      "---------------------------------------- - ----------------------------------------\n",
      "tensor_name:  final_layer/b\n",
      "tensor_name:  final_layer/w\n",
      "---------------------------------------- - ----------------------------------------\n",
      "tensor_name:  final_layer/b\n",
      "[-1.3819424]\n",
      "tensor_name:  final_layer/w\n",
      "[[-0.30363435]\n",
      " [ 0.34300038]\n",
      " [ 1.0742702 ]\n",
      " [-0.38556582]\n",
      " [-0.1977814 ]\n",
      " [-0.4899265 ]\n",
      " [ 0.766434  ]\n",
      " [ 0.57979876]\n",
      " [ 0.8123569 ]\n",
      " [-0.6349885 ]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.framework import graph_util\n",
    "\n",
    "\n",
    "\n",
    "def test():\n",
    "    with tf.Graph().as_default() as g_1: \n",
    "        ckpt = tf.train.get_checkpoint_state('./log/m1/') \n",
    "        with tf.Session(graph=g_1) as sess: \n",
    "\n",
    "            saver = tf.train.import_meta_graph('./log/m1/model_1.ckpt.meta') \n",
    "            print(ckpt.model_checkpoint_path)\n",
    "            saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "    #         writer = tf.summary.FileWriter(\"./log\", sess.graph)\n",
    "    #         print(sess.graph.get_all_collection_keys())\n",
    "    #         print(sess.graph.get_collection('variables'))\n",
    "    #         print(sess.graph.get_collection('trainable_variables'))\n",
    "    #         print(sess.graph.get_tensor_by_name('l1/out:0'))\n",
    "            input = sess.graph.get_tensor_by_name('Placeholder:0')\n",
    "            output = sess.graph.get_tensor_by_name('l1/out:0')\n",
    "            print(sess.run(output,{input:for_input}))\n",
    "    #         print(sess.graph_def)\n",
    "            g1def = graph_util.convert_variables_to_constants( \n",
    "                sess, \n",
    "                sess.graph_def, \n",
    "    #             [\"l1/out\",'l2/out'])\n",
    "                [\"l1/out\"])\n",
    "\n",
    "    with tf.Graph().as_default() as g_2: \n",
    "        with tf.Session(graph=g_1) as sess: \n",
    "            saver = tf.train.import_meta_graph('./log/m2/model_2.ckpt.meta') \n",
    "            saver.restore(sess, './log/m2/model_2.ckpt')\n",
    "            input = sess.graph.get_tensor_by_name('Placeholder:0')\n",
    "            output = sess.graph.get_tensor_by_name('l1/out:0')\n",
    "            print(sess.run(output,{input:for_input}))\n",
    "    #         print(sess.graph_def)\n",
    "            g2def = graph_util.convert_variables_to_constants( \n",
    "                sess, \n",
    "                sess.graph_def, \n",
    "                [\"l1/out\"])\n",
    "\n",
    "\n",
    "    with tf.Graph().as_default() as g_comb: \n",
    "        with tf.Session(graph=g_comb) as sess: \n",
    "            x1 = tf.placeholder(tf.float32, name=\"input_1\")\n",
    "            x2 = tf.placeholder(tf.float32, name='input_2')\n",
    "            out1 = tf.import_graph_def(g1def,input_map={\"Placeholder:0\": x1}, return_elements=[\"l1/out:0\"])[0]\n",
    "            out2 = tf.import_graph_def(g2def,input_map={\"Placeholder:0\": x2}, return_elements=[\"l1/out:0\"])[0]\n",
    "            print(out1)\n",
    "            print(out2)\n",
    "#             pdb.set_trace()\n",
    "            with tf.name_scope('final_layer') as scope:\n",
    "                w = tf.Variable(tf.random_normal([10, 1]),name='w')\n",
    "                b = tf.Variable(tf.random_normal([1]),name='b')\n",
    "                final_out = tf.nn.sigmoid(tf.matmul(tf.concat([out1,out2],1), w) + b, name='final_out')\n",
    "\n",
    "            saver = tf.train.Saver()\n",
    "\n",
    "\n",
    "            writer = tf.summary.FileWriter(\"./log\", sess.graph)\n",
    "            print(sess.run(out1,{x1:for_input,x2:for_input}))\n",
    "            print((sess.graph.get_tensor_by_name('import/l1/w:0')).eval())\n",
    "            print((sess.graph.get_tensor_by_name('import_1/l1/w:0')).eval())\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            \n",
    "            save_path = saver.save(sess, './log/comb/main.ckpt')\n",
    "            print(\"Model saved in path: %s\" % './log/comb/main.ckpt')\n",
    "\n",
    "test()   \n",
    "show_ckpt('./log/comb/main.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[[ 2.1081982  -0.0653644   0.71789426 -0.8337884   0.49091208]\n",
    " [-0.79259986 -0.57869947  2.2429605  -0.88159746 -1.350748  ]]\n",
    "\n",
    "[[-1.3923197  -1.0091283  -0.604495   -1.1805317  -1.4689256 ]\n",
    " [-0.26353896  0.56431895  0.8425082  -1.6075876   0.760832  ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mW0509 15:37:45.916058 Reloader tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[0mW0509 15:37:45.916058 140716453242624 tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[33mW0509 15:37:45.923168 Reloader tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[0mW0509 15:37:45.923167 140716453242624 tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[33mW0509 15:37:45.929723 Reloader tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[0mW0509 15:37:45.929723 140716453242624 tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[33mW0509 15:37:45.932856 Reloader tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[0mW0509 15:37:45.932856 140716453242624 tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[33mW0509 15:37:45.936552 Reloader tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[0mW0509 15:37:45.936552 140716453242624 tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[33mW0509 15:37:45.939900 Reloader tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[0mW0509 15:37:45.939899 140716453242624 tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[33mW0509 15:37:45.943561 Reloader tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[0mW0509 15:37:45.943561 140716453242624 tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[33mW0509 15:37:45.947277 Reloader tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[0mW0509 15:37:45.947277 140716453242624 tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[33mW0509 15:37:45.950681 Reloader tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[0mW0509 15:37:45.950681 140716453242624 tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[33mW0509 15:37:45.953883 Reloader tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[0mW0509 15:37:45.953882 140716453242624 tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[33mW0509 15:37:45.956880 Reloader tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[0mW0509 15:37:45.956880 140716453242624 tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[33mW0509 15:37:45.960006 Reloader tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[0mW0509 15:37:45.960005 140716453242624 tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[33mW0509 15:37:45.963040 Reloader tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[0mW0509 15:37:45.963040 140716453242624 tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[33mW0509 15:37:45.966447 Reloader tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[0mW0509 15:37:45.966447 140716453242624 tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[33mW0509 15:37:45.969498 Reloader tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[0mW0509 15:37:45.969498 140716453242624 tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[33mW0509 15:37:45.972871 Reloader tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[0mW0509 15:37:45.972871 140716453242624 tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[33mW0509 15:37:45.976453 Reloader tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[0mW0509 15:37:45.976453 140716453242624 tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[33mW0509 15:37:45.980017 Reloader tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[0mW0509 15:37:45.980016 140716453242624 tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[33mW0509 15:37:45.983369 Reloader tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[0mW0509 15:37:45.983369 140716453242624 tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[33mW0509 15:37:45.986768 Reloader tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[0mW0509 15:37:45.986768 140716453242624 tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[33mW0509 15:37:45.989609 Reloader tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[0mW0509 15:37:45.989609 140716453242624 tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[33mW0509 15:37:45.992602 Reloader tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[0mW0509 15:37:45.992602 140716453242624 tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[33mW0509 15:37:45.995585 Reloader tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[0mW0509 15:37:45.995585 140716453242624 tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[33mW0509 15:37:45.998234 Reloader tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[0mW0509 15:37:45.998234 140716453242624 tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[33mW0509 15:37:46.000877 Reloader tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[0mW0509 15:37:46.000877 140716453242624 tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[33mW0509 15:37:46.003537 Reloader tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[0mW0509 15:37:46.003537 140716453242624 tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[33mW0509 15:37:46.006063 Reloader tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[0mW0509 15:37:46.006063 140716453242624 tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[33mW0509 15:37:46.008588 Reloader tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[0mW0509 15:37:46.008588 140716453242624 tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[33mW0509 15:37:46.012090 Reloader tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[0mW0509 15:37:46.012090 140716453242624 tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[33mW0509 15:37:46.014979 Reloader tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[0mW0509 15:37:46.014979 140716453242624 tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[33mW0509 15:37:46.017693 Reloader tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[0mW0509 15:37:46.017693 140716453242624 tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[33mW0509 15:37:46.020228 Reloader tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[0mW0509 15:37:46.020228 140716453242624 tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mW0509 15:37:46.023013 Reloader tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[0mW0509 15:37:46.023013 140716453242624 tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[33mW0509 15:37:46.025897 Reloader tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[0mW0509 15:37:46.025897 140716453242624 tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "TensorBoard 1.11.0 at http://woody-System-Product-Name:6006 (Press CTRL+C to quit)\n",
      "\u001b[33mW0509 15:37:51.678869 Thread-1 application.py:300] path /[[getImageSrc(feat.name)]] not found, sending 404\n",
      "\u001b[0mW0509 15:37:51.678869 140716444587776 application.py:300] path /[[getImageSrc(feat.name)]] not found, sending 404\n",
      "\u001b[33mW0509 15:37:51.679747 Thread-2 application.py:300] path /[[getCompareImageSrc(feat.name)]] not found, sending 404\n",
      "\u001b[0mW0509 15:37:51.679747 140716436195072 application.py:300] path /[[getCompareImageSrc(feat.name)]] not found, sending 404\n",
      "\u001b[33mW0509 15:37:51.680482 Thread-3 application.py:300] path /[[getSeqImageSrc(seqfeat.name, seqNumber)]] not found, sending 404\n",
      "\u001b[0mW0509 15:37:51.680481 140716427802368 application.py:300] path /[[getSeqImageSrc(seqfeat.name, seqNumber)]] not found, sending 404\n",
      "\u001b[33mW0509 15:37:51.680804 Thread-4 application.py:300] path /[[getCompareSeqImageSrc(seqfeat.name, seqNumber)]] not found, sending 404\n",
      "\u001b[0mW0509 15:37:51.680804 140716214843136 application.py:300] path /[[getCompareSeqImageSrc(seqfeat.name, seqNumber)]] not found, sending 404\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir ./log/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./log/m1/model_1.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ./log/m1/model_1.ckpt\n",
      "[[0.6998952  0.42184424 0.9357194  0.6366171  0.6916014 ]\n",
      " [0.767608   0.43084663 0.9307523  0.62652844 0.7272433 ]\n",
      " [0.29320782 0.33458742 0.9794445  0.59869456 0.39708373]]\n",
      "INFO:tensorflow:Froze 2 variables.\n",
      "INFO:tensorflow:Converted 2 variables to const ops.\n",
      "INFO:tensorflow:Restoring parameters from ./log/m2/model_2.ckpt\n",
      "[[0.5864791  0.41253614 0.83595526 0.12428858 0.17414013]\n",
      " [0.5452906  0.36942482 0.81458646 0.12073739 0.13997047]\n",
      " [0.7179354  0.6464656  0.92809665 0.08064602 0.448617  ]]\n",
      "INFO:tensorflow:Froze 2 variables.\n",
      "INFO:tensorflow:Converted 2 variables to const ops.\n",
      "[[0.6998952  0.42184424 0.9357194  0.6366171  0.6916014 ]\n",
      " [0.767608   0.43084663 0.9307523  0.62652844 0.7272433 ]\n",
      " [0.29320782 0.33458742 0.9794445  0.59869456 0.39708373]]\n",
      "[[ 2.1081982  -0.0653644   0.71789426 -0.8337884   0.49091208]\n",
      " [-0.79259986 -0.57869947  2.2429605  -0.88159746 -1.350748  ]]\n",
      "[[-1.3923197  -1.0091283  -0.604495   -1.1805317  -1.4689256 ]\n",
      " [-0.26353896  0.56431895  0.8425082  -1.6075876   0.760832  ]]\n",
      "INFO:tensorflow:Restoring parameters from ./log/comb/main.ckpt\n",
      "[[-0.30363435]\n",
      " [ 0.34300038]\n",
      " [ 1.0742702 ]\n",
      " [-0.38556582]\n",
      " [-0.1977814 ]\n",
      " [-0.4899265 ]\n",
      " [ 0.766434  ]\n",
      " [ 0.57979876]\n",
      " [ 0.8123569 ]\n",
      " [-0.6349885 ]]\n"
     ]
    }
   ],
   "source": [
    "def test_restore():\n",
    "    with tf.Graph().as_default() as g_1: \n",
    "        ckpt = tf.train.get_checkpoint_state('./log/m1/') \n",
    "        with tf.Session(graph=g_1) as sess: \n",
    "\n",
    "            saver = tf.train.import_meta_graph('./log/m1/model_1.ckpt.meta') \n",
    "            print(ckpt.model_checkpoint_path)\n",
    "            saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "            input = sess.graph.get_tensor_by_name('Placeholder:0')\n",
    "            output = sess.graph.get_tensor_by_name('l1/out:0')\n",
    "            print(sess.run(output,{input:for_input}))\n",
    "            g1def = graph_util.convert_variables_to_constants( \n",
    "                sess, \n",
    "                sess.graph_def, \n",
    "                [\"l1/out\"])\n",
    "\n",
    "    with tf.Graph().as_default() as g_2: \n",
    "        with tf.Session(graph=g_1) as sess: \n",
    "            saver = tf.train.import_meta_graph('./log/m2/model_2.ckpt.meta') \n",
    "            saver.restore(sess, './log/m2/model_2.ckpt')\n",
    "            input = sess.graph.get_tensor_by_name('Placeholder:0')\n",
    "            output = sess.graph.get_tensor_by_name('l1/out:0')\n",
    "            print(sess.run(output,{input:for_input}))\n",
    "            g2def = graph_util.convert_variables_to_constants( \n",
    "                sess, \n",
    "                sess.graph_def, \n",
    "                [\"l1/out\"])\n",
    "\n",
    "\n",
    "    with tf.Graph().as_default() as g_comb: \n",
    "        with tf.Session(graph=g_comb) as sess: \n",
    "            x1 = tf.placeholder(tf.float32, name=\"input_1\")\n",
    "            x2 = tf.placeholder(tf.float32, name='input_2')\n",
    "            out1 = tf.import_graph_def(g1def,input_map={\"Placeholder:0\": x1}, return_elements=[\"l1/out:0\"])[0]\n",
    "            out2 = tf.import_graph_def(g2def,input_map={\"Placeholder:0\": x2}, return_elements=[\"l1/out:0\"])[0]\n",
    "#             pdb.set_trace()\n",
    "            with tf.name_scope('final_layer') as scope:\n",
    "                w = tf.Variable(tf.random_normal([10, 1]),name='w')\n",
    "                b = tf.Variable(tf.random_normal([1]),name='b')\n",
    "                final_out = tf.nn.sigmoid(tf.matmul(tf.concat([out1,out2],1), w) + b, name='final_out')\n",
    "\n",
    "            saver = tf.train.Saver()\n",
    "\n",
    "\n",
    "            writer = tf.summary.FileWriter(\"./log\", sess.graph)\n",
    "            print(sess.run(out1,{x1:for_input,x2:for_input}))\n",
    "            print((sess.graph.get_tensor_by_name('import/l1/w:0')).eval())\n",
    "            print((sess.graph.get_tensor_by_name('import_1/l1/w:0')).eval())\n",
    "            \n",
    "            save_path = saver.restore(sess, './log/comb/main.ckpt')\n",
    "            print(w.eval())\n",
    "test_restore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_name:  final_layer/b\n",
    "[-1.3819424]\n",
    "tensor_name:  final_layer/w\n",
    "[[-0.30363435]\n",
    " [ 0.34300038]\n",
    " [ 1.0742702 ]\n",
    " [-0.38556582]\n",
    " [-0.1977814 ]\n",
    " [-0.4899265 ]\n",
    " [ 0.766434  ]\n",
    " [ 0.57979876]\n",
    " [ 0.8123569 ]\n",
    " [-0.6349885 ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.Graph?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------- - ----------------------------------------\n",
      "tensor_name:  batch_normalization_4/gamma/Adam\n",
      "tensor_name:  l2_conv3d/kernel/Adam\n",
      "tensor_name:  l2_conv3d/b/Adam\n",
      "tensor_name:  batch_normalization_5/beta/Adam\n",
      "tensor_name:  batch_normalization/gamma\n",
      "tensor_name:  l4_conv3d/kernel/Adam_1\n",
      "tensor_name:  batch_normalization_4/beta/Adam_1\n",
      "tensor_name:  batch_normalization_2/gamma\n",
      "tensor_name:  batch_normalization_3/moving_mean\n",
      "tensor_name:  l1_conv3d/kernel/Adam\n",
      "tensor_name:  batch_normalization/beta/Adam_1\n",
      "tensor_name:  l8_fc/b/Adam_1\n",
      "tensor_name:  batch_normalization/moving_variance\n",
      "tensor_name:  batch_normalization_6/moving_variance\n",
      "tensor_name:  batch_normalization/gamma/Adam_1\n",
      "tensor_name:  l7_fc/w/Adam_1\n",
      "tensor_name:  batch_normalization_2/beta/Adam_1\n",
      "tensor_name:  l6_fc/w\n",
      "tensor_name:  batch_normalization_1/beta\n",
      "tensor_name:  l5_conv3d/b/Adam\n",
      "tensor_name:  batch_normalization_3/beta/Adam_1\n",
      "tensor_name:  beta1_power\n",
      "tensor_name:  l8_fc/b\n",
      "tensor_name:  batch_normalization_5/moving_variance\n",
      "tensor_name:  batch_normalization_1/beta/Adam_1\n",
      "tensor_name:  l2_conv3d/kernel/Adam_1\n",
      "tensor_name:  l2_conv3d/b\n",
      "tensor_name:  l8_fc/w/Adam\n",
      "tensor_name:  batch_normalization_3/gamma/Adam_1\n",
      "tensor_name:  batch_normalization_5/beta/Adam_1\n",
      "tensor_name:  l5_conv3d/b\n",
      "tensor_name:  l3_conv3d/kernel/Adam\n",
      "tensor_name:  l3_conv3d/b/Adam\n",
      "tensor_name:  batch_normalization_2/moving_variance\n",
      "tensor_name:  l5_conv3d/b/Adam_1\n",
      "tensor_name:  l6_fc/b/Adam_1\n",
      "tensor_name:  batch_normalization_2/beta/Adam\n",
      "tensor_name:  l5_conv3d/kernel/Adam\n",
      "tensor_name:  l4_conv3d/kernel/Adam\n",
      "tensor_name:  l6_fc/b\n",
      "tensor_name:  batch_normalization_3/moving_variance\n",
      "tensor_name:  l7_fc/w/Adam\n",
      "tensor_name:  batch_normalization_6/gamma/Adam\n",
      "tensor_name:  batch_normalization/beta/Adam\n",
      "tensor_name:  l1_conv3d/b/Adam\n",
      "tensor_name:  l7_fc/w\n",
      "tensor_name:  batch_normalization_6/beta\n",
      "tensor_name:  batch_normalization_4/beta/Adam\n",
      "tensor_name:  batch_normalization_3/beta/Adam\n",
      "tensor_name:  batch_normalization_5/beta\n",
      "tensor_name:  l2_conv3d/kernel\n",
      "tensor_name:  l5_conv3d/kernel\n",
      "tensor_name:  batch_normalization_1/moving_variance\n",
      "tensor_name:  batch_normalization_4/gamma\n",
      "tensor_name:  l6_fc/w/Adam_1\n",
      "tensor_name:  l3_conv3d/b\n",
      "tensor_name:  l3_conv3d/kernel/Adam_1\n",
      "tensor_name:  batch_normalization_2/gamma/Adam_1\n",
      "tensor_name:  l1_conv3d/kernel\n",
      "tensor_name:  batch_normalization_4/moving_variance\n",
      "tensor_name:  batch_normalization_1/gamma/Adam_1\n",
      "tensor_name:  batch_normalization_1/gamma/Adam\n",
      "tensor_name:  batch_normalization_5/gamma/Adam_1\n",
      "tensor_name:  l4_conv3d/kernel\n",
      "tensor_name:  batch_normalization_2/gamma/Adam\n",
      "tensor_name:  l8_fc/w\n",
      "tensor_name:  beta2_power\n",
      "tensor_name:  batch_normalization/moving_mean\n",
      "tensor_name:  batch_normalization_4/beta\n",
      "tensor_name:  l1_conv3d/b/Adam_1\n",
      "tensor_name:  batch_normalization/beta\n",
      "tensor_name:  batch_normalization_1/beta/Adam\n",
      "tensor_name:  batch_normalization_6/gamma\n",
      "tensor_name:  batch_normalization_6/beta/Adam\n",
      "tensor_name:  batch_normalization/gamma/Adam\n",
      "tensor_name:  batch_normalization_4/gamma/Adam_1\n",
      "tensor_name:  batch_normalization_6/moving_mean\n",
      "tensor_name:  l1_conv3d/b\n",
      "tensor_name:  batch_normalization_2/moving_mean\n",
      "tensor_name:  batch_normalization_2/beta\n",
      "tensor_name:  batch_normalization_4/moving_mean\n",
      "tensor_name:  batch_normalization_3/gamma\n",
      "tensor_name:  batch_normalization_6/beta/Adam_1\n",
      "tensor_name:  l4_conv3d/b/Adam\n",
      "tensor_name:  l1_conv3d/kernel/Adam_1\n",
      "tensor_name:  batch_normalization_1/gamma\n",
      "tensor_name:  l8_fc/b/Adam\n",
      "tensor_name:  l3_conv3d/b/Adam_1\n",
      "tensor_name:  l7_fc/b/Adam_1\n",
      "tensor_name:  l4_conv3d/b/Adam_1\n",
      "tensor_name:  l3_conv3d/kernel\n",
      "tensor_name:  l6_fc/b/Adam\n",
      "tensor_name:  batch_normalization_6/gamma/Adam_1\n",
      "tensor_name:  l7_fc/b/Adam\n",
      "tensor_name:  batch_normalization_1/moving_mean\n",
      "tensor_name:  batch_normalization_3/beta\n",
      "tensor_name:  l8_fc/w/Adam_1\n",
      "tensor_name:  batch_normalization_5/gamma/Adam\n",
      "tensor_name:  batch_normalization_5/gamma\n",
      "tensor_name:  batch_normalization_5/moving_mean\n",
      "tensor_name:  l7_fc/b\n",
      "tensor_name:  l5_conv3d/kernel/Adam_1\n",
      "tensor_name:  batch_normalization_3/gamma/Adam\n",
      "tensor_name:  l2_conv3d/b/Adam_1\n",
      "tensor_name:  l4_conv3d/b\n",
      "tensor_name:  l6_fc/w/Adam\n"
     ]
    }
   ],
   "source": [
    "show_ckpt('../nki_alff/log/model_mse_woody.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `tf.compat.v1` not found.\n"
     ]
    }
   ],
   "source": [
    "tf.compat.v1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_1 = tf.Graph()\n",
    "with g_1.as_default():\n",
    "  # Operations created in this scope will be added to `g_1`.\n",
    "  c = tf.constant(\"Node in g_1\")\n",
    "\n",
    "  # Sessions created in this scope will run operations from `g_1`.\n",
    "  sess_1 = tf.Session()\n",
    "\n",
    "g_2 = tf.Graph()\n",
    "with g_2.as_default():\n",
    "  # Operations created in this scope will be added to `g_2`.\n",
    "  d = tf.constant(\"Node in g_2\")\n",
    "\n",
    "# Alternatively, you can pass a graph when constructing a <a href=\"./../api_docs/python/tf/Session\"><code>tf.Session</code></a>:\n",
    "# `sess_2` will run operations from `g_2`.\n",
    "sess_2 = tf.Session(graph=g_2)\n",
    "\n",
    "assert c.graph is g_1\n",
    "assert sess_1.graph is g_1\n",
    "\n",
    "assert d.graph is g_2\n",
    "assert sess_2.graph is g_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
